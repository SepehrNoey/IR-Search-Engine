import normalizer

def tokenize(str: str):
    return str.split(normalizer.single_space)